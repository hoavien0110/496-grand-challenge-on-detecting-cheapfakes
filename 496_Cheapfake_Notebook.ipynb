{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [0 - Preparation](#0)\n",
    "    - [0.1 - Download LlaMA-Adpater V2 ](#0-1)\n",
    "    - [0.2 - Packages](#0-2)\n",
    "    - [0.3 - LlaMA Checkpoints](#0-3)\n",
    "- [1 - Context Generation](#1)\n",
    "    - [1.0 Load Llama-Adapter V2](#1-1)\n",
    "    - [1.1 Load weight](#1-2)\n",
    "- [2 - Text Clasification (RoBERTa)](#2)\n",
    "- [3 - Evaluation](#3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"test_acm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_file = zipfile.ZipFile(\"test_acm.zip\")\n",
    "# zip_file.extractall()\n",
    "# zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Download LLaMa-Adapter V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLaMA-Adapter'...\n",
      "remote: Enumerating objects: 1151, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 1151 (delta 9), reused 13 (delta 6), pack-reused 1126\u001b[K\n",
      "Receiving objects: 100% (1151/1151), 34.41 MiB | 7.46 MiB/s, done.\n",
      "Resolving deltas: 100% (541/541), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/OpenGVLab/LLaMA-Adapter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/LLaMA-Adapter/llama_adapter_v2_multimodal7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Adapter/llama_adapter_v2_multimodal7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
      "Collecting git+https://github.com/csuhan/timm_0_3_2.git (from -r requirements.txt (line 10))\n",
      "  Cloning https://github.com/csuhan/timm_0_3_2.git to /tmp/pip-req-build-wcsegbqh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/csuhan/timm_0_3_2.git /tmp/pip-req-build-wcsegbqh\n",
      "  Resolved https://github.com/csuhan/timm_0_3_2.git to commit bf33f97f767a38e1b56cdd9c6a22372468fb55a4\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 11))\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-06h8e1pq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-06h8e1pq\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch==2.0.0+cu117 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.0.0+cu117)\n",
      "Requirement already satisfied: torchvision==0.15.1+cu117 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.15.1+cu117)\n",
      "Requirement already satisfied: fairscale in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.13)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (10.2.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (4.9.0.80)\n",
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.22.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu117->-r requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu117->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu117->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu117->-r requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu117->-r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0+cu117->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.1+cu117->-r requirements.txt (line 3)) (1.26.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.15.1+cu117->-r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0+cu117->-r requirements.txt (line 2)) (3.28.3)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0+cu117->-r requirements.txt (line 2)) (18.1.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.110.0)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.13.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.13.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.21.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (3.8.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (3.9.15)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (2.6.4)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.3.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 8)) (0.29.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio->-r requirements.txt (line 8)) (11.0.3)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from clip==1.0->-r requirements.txt (line 11)) (6.2.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0->-r requirements.txt (line 11)) (2023.12.25)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.12.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (1.0.4)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (0.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 8)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 8)) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 8)) (2.16.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio->-r requirements.txt (line 8)) (0.36.3)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0->-r requirements.txt (line 11)) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.1+cu117->-r requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.15.1+cu117->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0+cu117->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 8)) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 8)) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/LLaMA-Adapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Install requirements package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cu117)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.28.3)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (18.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: Pyarrow in /opt/conda/lib/python3.10/site-packages (15.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from Pyarrow) (1.26.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python-headless) (1.26.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (5.26.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!pip install torch\n",
    "!pip install pandas\n",
    "!pip install Pyarrow\n",
    "!pip install transformers\n",
    "!pip install opencv-python-headless\n",
    "!pip install protobuf\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import gdown\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as npval_test_df\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, AutoModelForSequenceClassification, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path: str) -> list:\n",
    "    with open(path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến file test có context\n",
    "json_test_file = INPUT_FOLDER + \"/public_test_acm.json\"\n",
    "data = read_json(json_test_file)\n",
    "\n",
    "# Chuyển đổi dữ liệu thành DataFrame\n",
    "df_test = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Llama-Adapter V2 checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1LaQpjJsEdrD-9KhEEpYyXtx8HMsejjuR\n",
      "From (redirected): https://drive.google.com/uc?id=1LaQpjJsEdrD-9KhEEpYyXtx8HMsejjuR&confirm=t&uuid=47dd432e-b0f5-431b-9e8b-095519027fd1\n",
      "To: /media/weight-latest.zip\n",
      "100%|██████████████████████████████████████| 12.4G/12.4G [03:53<00:00, 53.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1LaQpjJsEdrD-9KhEEpYyXtx8HMsejjuR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = zipfile.ZipFile(\"weight-latest.zip\")\n",
    "zip_file.extractall()\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Context Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Load LLaMa-Adapter V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/LLaMA-Adapter/llama_adapter_v2_multimodal7b\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Adapter/llama_adapter_v2_multimodal7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/LLaMA-Adapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 393M/393M [00:03<00:00, 111MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMA-Adapter from ckpts/d26d107eec32127ac86ef1997cf7169de1c56a59c539fc1258c6798b969e289c_LORA-BIAS-7B-v21.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 890M/890M [00:20<00:00, 45.6MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable param: llama.layers.0.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.0.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.0.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.0.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.0.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.0.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.0.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.1.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.1.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.1.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.1.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.1.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.1.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.1.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.2.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.2.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.2.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.2.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.2.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.2.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.2.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.3.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.3.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.3.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.3.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.3.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.3.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.3.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.4.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.4.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.4.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.4.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.4.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.4.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.4.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.5.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.5.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.5.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.5.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.5.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.5.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.5.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.6.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.6.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.6.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.6.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.6.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.6.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.6.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.7.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.7.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.7.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.7.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.7.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.7.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.7.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.8.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.8.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.8.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.8.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.8.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.8.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.8.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.9.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.9.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.9.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.9.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.9.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.9.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.9.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.10.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.10.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.10.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.10.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.10.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.10.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.10.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.11.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.11.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.11.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.11.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.11.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.11.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.11.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.12.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.12.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.12.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.12.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.12.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.12.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.12.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.13.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.13.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.13.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.13.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.13.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.13.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.13.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.14.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.14.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.14.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.14.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.14.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.14.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.14.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.15.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.15.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.15.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.15.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.15.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.15.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.15.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.16.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.16.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.16.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.16.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.16.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.16.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.16.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.17.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.17.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.17.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.17.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.17.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.17.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.17.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.18.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.18.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.18.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.18.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.18.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.18.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.18.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.19.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.19.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.19.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.19.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.19.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.19.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.19.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.20.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.20.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.20.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.20.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.20.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.20.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.20.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.21.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.21.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.21.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.21.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.21.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.21.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.21.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.22.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.22.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.22.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.22.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.22.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.22.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.22.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.23.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.23.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.23.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.23.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.23.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.23.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.23.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.24.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.24.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.24.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.24.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.24.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.24.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.24.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.25.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.25.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.25.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.25.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.25.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.25.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.25.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.26.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.26.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.26.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.26.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.26.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.26.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.26.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.27.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.27.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.27.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.27.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.27.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.27.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.27.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.28.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.28.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.28.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.28.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.28.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.28.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.28.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.29.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.29.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.29.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.29.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.29.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.29.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.29.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.30.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.30.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.30.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.30.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.30.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.30.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.30.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.31.attention.wq.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.31.attention.wo.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.31.feed_forward.w1.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.31.feed_forward.w2.bias, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.31.feed_forward.w3.bias, torch.Size([11008]), torch.float32\n",
      "Trainable param: llama.layers.31.attention_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.layers.31.ffn_norm.weight, torch.Size([4096]), torch.float32\n",
      "Trainable param: llama.norm.weight, torch.Size([4096]), torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLaMA_adapter(\n",
       "  (clip): CLIP(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "      (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): Sequential(\n",
       "          (0): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 768)\n",
       "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (clip_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (clip_proj_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (visual_query): Embedding(10, 768)\n",
       "  (visual_blocks): ModuleList(\n",
       "    (0-7): 8 x Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (visual_proj): Linear(in_features=768, out_features=4096, bias=True)\n",
       "  (visual_proj_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  (adapter_query): Embedding(310, 4096)\n",
       "  (llama): Transformer(\n",
       "    (tok_embeddings): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x TransformerBlock(\n",
       "        (attention): Attention(\n",
       "          (wq): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (wk): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wv): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)\n",
       "          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)\n",
       "          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)\n",
       "          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)\n",
       "          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)\n",
       "          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)\n",
       "          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)\n",
       "          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=True)\n",
       "          (w2): Linear(in_features=11008, out_features=4096, bias=True)\n",
       "          (w3): Linear(in_features=4096, out_features=11008, bias=True)\n",
       "          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)\n",
       "          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)\n",
       "          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)\n",
       "          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)\n",
       "          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)\n",
       "          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)\n",
       "        )\n",
       "        (attention_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "    (output): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_dir = \"weight-latest/weight\"\n",
    "\n",
    "# choose from BIAS-7B, LORA-BIAS-7B, LORA-BIAS-7B-v21\n",
    "model, preprocess = llama.load(\"LORA-BIAS-7B-v21\", llama_dir, llama_type=\"7B\", device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_length = 1800  \n",
    "def inference(image_path, prompt1, prompt2):\n",
    "    # Handle image\n",
    "    img1 = Image.fromarray(cv2.imread(image_path))\n",
    "    img1 = preprocess(img1).unsqueeze(0).to(device)\n",
    "    \n",
    "    if len(prompt1) > max_length:\n",
    "        prompt1 = prompt1[:max_length] \n",
    "    prompt1 = llama.format_prompt(prompt1)\n",
    "    result1 = model.generate(img1, [prompt1])[0]\n",
    "\n",
    "    img2 = Image.fromarray(cv2.imread(image_path))\n",
    "    img2 = preprocess(img2).unsqueeze(0).to(device)\n",
    "    if len(prompt2) > max_length:\n",
    "        prompt2 = prompt2[:max_length] \n",
    "    prompt2 = llama.format_prompt(prompt2)\n",
    "    result2 = model.generate(img2, [prompt2])[0]\n",
    "\n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test_acm/images_test_acm/0.jpg\n",
      "context 1: In the image, a man is standing at a podium, giving a speech to a crowd of people. The man appears to be a politician, possibly Julian Castro, as he is wearing a suit and tie. The audience is engaged in the speech, with some of them holding flags, indicating that it might be a political event or rally. The man is speaking into a microphone, which is essential for amplifying his voice to reach the entire audience. The scene captures the public speaking aspect of politics and the importance of communication in conveying messages and ideas to the public.\n",
      "context 2: In the image, a man is standing at a podium, giving a speech to a crowd of people. The man appears to be the main subject of the photo, and he is likely the speaker at an event. The crowd is gathered around the speaker, attentively listening to his words. There are several people in the audience, some standing closer to the speaker and others further back. The scene suggests that the man giving the speech might be a public figure or a notable individual addressing the audience on a particular topic or occasion.\n",
      "1\n",
      "test_acm/images_test_acm/1.jpg\n",
      "context 1: In the image, a group of people is gathered in the street, celebrating the victory of their candidate in the Zanzibari presidential election. A man is sitting on top of a truck, and others are standing around him, waving and enjoying the festivities. The atmosphere appears lively and joyful as the supporters come together to express their enthusiasm for the election outcome.\n",
      "context 2: The image shows a man sitting on top of a truck, wearing a yellow shirt, and surrounded by a group of people. The truck appears to be a part of a celebration, possibly for a political event. The man on the truck seems to be the center of attention, as the crowd of people gathers around him, watching and enjoying the festivities.\n",
      "2\n",
      "test_acm/images_test_acm/2.jpg\n",
      "context 1: It is not possible for me to determine the accuracy or relevance of the information provided in the image without further context or sources. I would suggest consulting reliable sources or contacting the relevant authorities to verify the information.\n",
      "context 2: The social media posts linked to an article published by Fox News in 2013, not a recent article about the Florida recount in November 2018. The article from 2013 discusses the impact of a new voter-related law in Florida, not the recount process that happened in 2018.\n",
      "3\n",
      "test_acm/images_test_acm/3.jpg\n",
      "context 1: The image shows Kirk Cameron, a well-known actor, musician, director, and devoted follower of Christ, speaking into a microphone. However, the content of the image does not provide any information about him being stricken with an extremely rare form of a disease. The description suggests that the image might have been edited or manipulated to include this information, which is not accurate.\n",
      "context 2: The image shows Kirk Cameron speaking at a podium, but the report claiming that he had converted to Islam and was now using a new name, Mohammad Kirk, was a hoax. This information was not true, and it was likely created to be humorous or sensationalist. It is important to be cautious when consuming online content and verify the accuracy and reliability of information before sharing it.\n",
      "4\n",
      "test_acm/images_test_acm/4.jpg\n",
      "context 1: The image depicts a group of men from the Maasai tribe, dressed in traditional red and black attire, standing in a field. They are performing a traditional jumping ritual, which is a part of a rite of passage to mark the transition to cultural junior elder within the Masai-Mara national reserve. The men are seen wearing sandals and are in various positions, some standing and others jumping. The scene captures the essence of their cultural heritage and the importance of these ceremonies in their community.\n",
      "context 2: In the image, a group of Masai men in Kenya's Narok county are participating in an initiation rite to become moran, the warrior class. They are dressed in traditional red and black attire, and some of them are holding sticks. The scene depicts a significant cultural event in their lives, as moran status confers respect, prestige, and responsibility within their community. The young men are standing in the dirt, likely in a dirt field, as they go through the rites to become part of the moran brotherhood.\n",
      "5\n",
      "test_acm/images_test_acm/5.jpg\n",
      "context 1: The image shows a person attaching \"skin\" to the head of a humanoid robot. The robot is designed to resemble a human and is made by Promobot, a service robotics manufacturer. The person appears to be an employee of Promobot, carefully and meticulously applying the \"skin\" to the robot's head. This process is essential for creating a realistic and lifelike appearance for the robot, making it more engaging and relatable to people.\n",
      "context 2: In the image, a person is carefully fitting an artificial skin onto the head of a robot. The person is using a pair of scissors to cut and shape the skin to ensure a perfect fit. The robot's head is placed on a table, and the person's hands are visible as they carefully apply the skin to the robot's head. This process might be part of a robotics project or an effort to humanize the robot.\n",
      "6\n",
      "test_acm/images_test_acm/6.jpg\n",
      "context 1: The image shows a bird, either a goose or a duck, lying down next to a small puppy. The puppy is lying on the ground, and the bird appears to be covering or partially covering the puppy with its wings, providing warmth and a sense of security. This act of the bird shows a caring and protective behavior towards the puppy, demonstrating the bond between animals in nature.\n",
      "context 2: The claim that \"it isn't unprecedented for birds and dogs to strike up friendships\" is false. While there have been instances of birds and dogs forming friendships, these relationships are quite rare and not the norm. Most often, birds and dogs are perceived as natural predators or competitors, and their interactions are often aggressive or territorial. It is important to note that the image in the post is not of a bird and a dog, but rather of two geese and a duck, which are not typical examples of birds and dogs forming friendships.\n",
      "7\n",
      "test_acm/images_test_acm/7.png\n",
      "context 1: The image shows a photograph of Ricky Ellsworth, a white woman who was killed by a black police officer in Minnesota. The photograph is accompanied by a caption that reads, \"I was also murdered by a Minnesota cop, where was my riot?\" This statement suggests that the woman's death was a result of police misconduct and that she was a victim of a police-related incident. The image and caption aim to raise awareness and discuss the issue of police brutality and the need for justice in such cases.\n",
      "context 2: The viral meme in question is a photo of a woman with the caption, \"I was also murdered by a police officer, where was my riot?\" The intention behind this meme is to raise awareness about police violence and racial injustice in the United States. However, the meme contains some inaccuracies and misinformation. Firstly, the woman in the photo is not a victim of police violence, as she is merely posing for the picture. Secondly, the meme implies that the woman was involved in a riot, which is not true. The woman in the photo is not participating in any form of protest or unrest. These inaccuracies in the meme could potentially lead to misunderstandings and misinterpretations of the intended message. It is essential to ensure that the content of such messages is accurate and well-researched to effectively convey the intended message and avoid misleading the audience.\n",
      "8\n",
      "test_acm/images_test_acm/8.png\n",
      "context 1: The image shows a young girl sitting on a hospital bed, with a large belly. She appears to be pregnant and is accompanied by a nurse who is standing next to her. The girl is wearing a green shirt and is visibly concerned about her situation. The photograph captures the emotional and physical challenges faced by the young girl, who is carrying a child that is not hers. The presence of the nurse suggests that she is receiving medical care and support during this difficult time.\n",
      "context 2: The image shows a young girl sitting on a hospital bed, wearing a green shirt. She is not pregnant. The photograph was originally posted by the Garrafão do Norte Facebook page in November 2016, and the girl is named Sandy. She is in a hospital room in Belém, Brazil.\n",
      "9\n",
      "test_acm/images_test_acm/9.jpg\n",
      "context 1: In the image, a man is brushing the mouth of a sarcophagus with a toothbrush. He is wearing a mask and a blue apron, indicating that he is a professional or taking precautions to avoid contamination. The scene takes place in a room with a dining table and a chair nearby. The man's actions suggest that he is cleaning or maintaining the sarcophagus, ensuring its preservation and hygiene.\n",
      "context 2: The image shows a man wearing a mask and a white coat, standing next to a statue. The man is using a tool, possibly a drill or a chisel, to work on the statue. There are several other statues in the scene, some of which are also being worked on by the man. The presence of multiple statues and the ongoing restoration work suggest that this could be a museum or a site where ancient artifacts are being conserved and restored to their original condition.\n",
      "10\n",
      "test_acm/images_test_acm/10.jpg\n",
      "context 1: In the image, President Trump is standing on a stage with a group of people, including police officers, while speaking to them. He is wearing a suit and tie, and he appears to be addressing the crowd on the subject of border security. The scene takes place near a road, with several trucks and a car visible in the background. The presence of the police officers and the context of the speech suggest that this event is related to the ongoing discussion about immigration and border control.\n",
      "context 2: In the image, President Trump is standing on a patch of dirt, surrounded by a group of people, including police officers. He is wearing a black jacket and is giving a speech. The scene takes place near a fence, which is likely part of the border between the United States and Mexico. The group of people, including the police officers, are listening to the President's speech attentively.\n",
      "11\n",
      "test_acm/images_test_acm/11.jpg\n",
      "context 1: The image shows a row of parked tuk-tuks in Bangkok, Thailand. These vehicles are typically used for transporting tourists around the city. However, due to travel bans and border closures during the pandemic, the tuk-tuks are now idle and not in use. The situation has affected the income of the drivers and other businesses that rely on tourism. The image highlights the impact of the pandemic on local economies and the disruption of travel and tourism activities in the city.\n",
      "context 2: The image shows a row of parked tuk-tuk cars in Bangkok, but it is important to note that there are no tourists visible in the scene. This could indicate that the tuk-tuk drivers are waiting for customers or that the area is not a popular tourist destination at the time the photo was taken. It is essential to consider the context of the image and the time it was captured when interpreting the situation.\n",
      "12\n",
      "test_acm/images_test_acm/12.jpg\n",
      "context 1: The image is a black and white photograph of a city street, taken in 1989. The street is surrounded by tall buildings, and there is a large roundabout in the middle of the city. The roundabout has a distinctive hole in the middle, which gives it the nickname \"Hole in the Road.\"There are several cars and a bus driving on the street, with some cars positioned closer to the hole in the roundabout. A traffic light can be seen on the left side of the street, and a clock is mounted on a nearby building. The scene captures the essence of urban life and transportation in the city.\n",
      "context 2: The image captures a busy city street in Sheffield, England, with a large roundabout at the center. The roundabout is surrounded by tall buildings, creating an urban atmosphere. The street is bustling with traffic, including numerous cars and a bus, as well as pedestrians walking along the sidewalks. There are several traffic lights positioned throughout the scene to manage the flow of vehicles and ensure safety for pedestrians. The presence of a clock in the image suggests that it might be a public space or a focal point for the city. Overall, the scene depicts a lively city street with a mix of transportation and people going about their daily lives.\n",
      "13\n",
      "test_acm/images_test_acm/13.jpg\n",
      "context 1: The image depicts a lively market scene in Istanbul, Turkey, with a group of people shopping and walking around. There are several individuals visible, some carrying handbags and backpacks, while others are simply enjoying the bustling atmosphere. A food cart is parked in the middle of the market, offering a variety of food items to the shoppers. The market is situated in a busy area, with a mix of people walking around and interacting with each other. The presence of a food cart and the crowd of people suggest that this is a popular spot for locals and tourists alike to explore and purchase fresh produce and delicious food.\n",
      "context 2: The image depicts a lively street scene in Istanbul's Eminonu district, where a street vendor is selling traditional Turkish pastries called \"Simit\" to a group of people. The vendor is standing next to a cart, and the customers are walking by, likely enjoying the local food offerings.In the background, there are several other people walking around, contributing to the bustling atmosphere of the area. A few handbags can be seen among the crowd, indicating that some of the people might be tourists or locals going about their daily activities. The overall scene captures the essence of a vibrant street market in Istanbul, where people can find delicious food and engage in social interactions.\n",
      "14\n",
      "test_acm/images_test_acm/14.jpg\n",
      "context 1: This statement is concerning as it appears to advocate for the use of force against individuals who did not attend the rally. It is important to note that public figures should express themselves in a manner that does not incite violence or encourage harm against others. It is essential to promote peaceful discourse and respectful disagreement in a democratic society.\n",
      "context 2: The image of the man standing at the podium with a flag in the background is not related to the original image of a ticket to Trump's rally and arrest. The second image is a fabrication intended to poke fun at the president over disappointing rally attendance. The original image, however, shows a man holding a ticket to Trump's rally and an arrest caption. It is important to note that the original image is not an actual photograph of the president but a fake created to make a joke about the president's rally attendance.\n",
      "15\n",
      "test_acm/images_test_acm/15.jpg\n",
      "context 1: The image features a mural of a girl's face painted on the side of a building, with a man standing on a ladder, possibly working on the mural or observing it. The mural is located in San Francisco, and it seems to be a part of a larger street art scene in the area. Thunberg, a famous activist, already has several murals dedicated to him around the world, including one in San Francisco. This mural, featuring a girl's face, might be another addition to the city's street art scene or a tribute to a specific individual or cause.\n",
      "context 2: The latest mural in San Francisco features a portrait of famous climate activist Greta Thunberg. The mural is painted on the side of a building, capturing the attention of passersby. A man is standing on a ladder, painting the mural, while another person is sitting on a ladder nearby. The mural showcases the city's commitment to environmental activism and raises awareness about the importance of climate change.\n",
      "16\n",
      "test_acm/images_test_acm/16.jpg\n",
      "context 1: On the same day in South Africa, a bird walks along Durban's empty shore where a ban on gatherings kept revellers at bay.\n",
      "context 2: The image features a picturesque beach scene with a bird walking along the shoreline. The beach is expansive and empty, providing a serene atmosphere. In the background, there are several high-rise buildings, adding a touch of urban development to the scene. The combination of the empty beach and the cityscape creates a unique and visually appealing contrast.\n",
      "17\n",
      "test_acm/images_test_acm/17.jpg\n",
      "context 1: The image features a woman dressed in green and white, the colors of the Nigerian flag, performing a dance in front of a crowd. She is twirling a hula hoop, showcasing her skills and adding excitement to the event. The woman is surrounded by several other people, who are likely spectators or participants in the celebration. The scene takes place in a field, where the gathering seems to be focused on enjoying the performance and the festive atmosphere.\n",
      "context 2: The image captures a lively performance by the Independence Band in Abuja, Nigeria, during the country's 60th Independence Celebration on October 1, 2020. The band is made up of several musicians, dancers, and a hula hoop artist, all dressed in matching green and white outfits. The performers are energetically playing their instruments and dancing, creating a joyful atmosphere. The hula hoop artist adds an exciting twist to the performance, twirling her hoop with skill and precision. The audience, consisting of several people, is watching the performance with interest and enjoying the spectacle.\n",
      "18\n",
      "test_acm/images_test_acm/18.jpg\n",
      "context 1: In the image, a man is diving into the Neretva river in Mostar, Bosnia and Herzegovina, from a height. He is wearing a wetsuit and appears to be in mid-air as he jumps into the water. The scene is quite thrilling and captivating, as it is not a typical sight to see someone diving from such a height into the river. The man's dive is surrounded by a crowd of people who are watching the exciting moment. The onlookers are scattered around the area, some standing closer to the river, while others are further away. The crowd seems to be enjoying the spectacle and the adrenaline rush it brings.\n",
      "context 2: The image captures an exciting moment during the 454th traditional diving competition in Mostar, Bosnia-Herzegovina. A man is seen jumping off the Old Bridge into the Neretva river, while a large crowd of spectators watches the thrilling event. The crowd is spread out along the riverbank, with some people standing closer to the bridge and others further away. The scene is filled with anticipation and excitement as the diver prepares to make his daring leap into the river.\n",
      "19\n",
      "test_acm/images_test_acm/19.jpg\n",
      "context 1: The image shows a group of people, including asylum seekers, lining up outside a building, possibly to enter or receive assistance. They are standing in a line, with some people closer to the building and others further back. There are a few individuals carrying backpacks, indicating that they might be carrying their belongings or supplies. The scene suggests that these people are seeking help, possibly due to a recent influx of asylum seekers in the area.\n",
      "context 2: The image shows a group of people, including asylum seekers, lined up outside a building, possibly near an airport or a border crossing. They are waiting in a queue, with some of them holding their belongings, such as handbags and backpacks. The scene suggests that these individuals are seeking entry into the United States or another country for various reasons, including seeking protection and a better life.\n",
      "20\n",
      "test_acm/images_test_acm/20.jpg\n",
      "context 1: Martin Fayulu, the opposition leader and runner-up in the election, had demanded a manual recount of the results.\n",
      "context 2: In the image, a crowd of people is gathered around a man in a suit, who appears to be a politician or a public figure. The man is walking with a folder in his hand, possibly holding important documents or evidence. The crowd consists of various individuals, some of whom are wearing ties, indicating a formal or professional setting. The scene suggests that the man is making a statement or addressing the crowd, possibly discussing an important issue or sharing his thoughts with the public.\n",
      "21\n",
      "test_acm/images_test_acm/21.jpg\n",
      "context 1: The image features a woman standing on a street in London, looking at a large billboard that pays tribute to Captain Sir Tom Moore. The billboard is located in Piccadilly Circus, which is a famous street junction in central London. The woman appears to be observing the tribute to Captain Sir Tom Moore, who was a notable figure in the community.\n",
      "context 2: The image features a woman playing the violin in the middle of a city street, surrounded by tall buildings. She is dressed in black and appears to be the center of attention as she performs. The scene takes place in front of a large electronic billboard, which is displaying a tribute to Captain Sir Tom Moore. There are several other people in the scene, some of them standing close to the woman and others further away. A handbag can be seen near one of the individuals, and a tie is visible on another person. The woman's performance seems to be capturing the interest of the people around her, creating a lively atmosphere in the urban setting.\n",
      "22\n",
      "test_acm/images_test_acm/22.jpg\n",
      "context 1: The image features a small brown and white dog, Bailey, sitting on a wooden bench in Regent's Park, London. Bailey is holding a green ball in his mouth, likely having just finished playing with it. The park is a lively and popular location, with several people and bicycles visible in the background. Some of the people are walking or standing, while others are riding bicycles, making the atmosphere lively and bustling. The scene captures a typical day in the park, with people enjoying their time outdoors and their pets playing and resting.\n",
      "context 2: The image features a small brown and white dog, Bailey, sitting on a wooden bench in Regent's Park, London. Bailey is holding a green ball in his mouth, possibly playing fetch or enjoying a game of fetch with its owner. The park is a lush green field, providing a pleasant and relaxing environment for the dog to play and explore.\n",
      "23\n",
      "test_acm/images_test_acm/23.png\n",
      "context 1: The image shows a video on a social media platform, with people in China tearing down a 5G tower in an attempt to stop the spread of COVID-19 coronavirus disease. The post has received several comments, with one person saying \"The Chinese are destroying the 5G tower in an attempt to stop the spread of COVID-19.\".\n",
      "context 2: The image shows a group of protesters in Hong Kong in August 2019, with some of them holding umbrellas. The protesters are tearing down a surveillance tower, which is a symbol of the ongoing protests against the Chinese government's influence in Hong Kong. The presence of umbrellas suggests that it might be raining or drizzling during the protest. The protesters are actively participating in the demonstration, expressing their dissatisfaction and demanding change.\n",
      "24\n",
      "test_acm/images_test_acm/24.jpg\n",
      "context 1: The image shows a group of people celebrating and waving flags in a room. The flags they are holding are yellow and red, which are the colors of the Spanish flag. The crowd is gathered together, expressing their joy and support for a cause. The event appears to be a political gathering, as some people are holding signs with messages related to the event. The attendees are excited and united in their enthusiasm, creating a lively and energetic atmosphere.\n",
      "context 2: The image shows a group of people gathered together, with many of them holding up flags. These people are supporters of Spain's anti-immigrant, populist Vox party, which won 12 seats in recent elections - its first in any Spanish legislative body. The crowd is celebrating and expressing their enthusiasm for the party, as they wave their flags and gather together in a show of unity and support.\n",
      "25\n",
      "test_acm/images_test_acm/25.jpg\n",
      "context 1: The image shows a close-up of a large asteroid, but it does not provide any information about the potential threat of it hitting Earth in April 2020. It is essential to note that while the image is of an asteroid, the caption does not provide any context related to the potential impact of Asteroid 52768 (1998 OR2) on Earth. It is important to verify the accuracy and context of such information through reliable sources and not rely solely on the image.\n",
      "context 2: The image features a close-up view of the asteroid Eros, which is a small, rocky object in space. The asteroid has a distinct saddle shape, with a large crater in the middle and smaller craters surrounding it. The surface of the asteroid appears to be dark and rocky, with a mix of light and dark areas. The image provides a detailed look at the unique topography of this celestial body.\n",
      "26\n",
      "test_acm/images_test_acm/26.jpg\n",
      "context 1: The photograph features a group of monkeys sitting and standing on rocks in a forest setting. There are at least 13 monkeys visible in the image, with some of them sitting close together while others are scattered around the rocks. The monkeys appear to be socializing and enjoying their time in the natural environment. The scene captures the essence of wildlife and the monkeys' natural habitat.\n",
      "context 2: The photograph does not show a group of monkeys, but rather a collection of dolls from the \"Inari Foxes\" series. The dolls are arranged in a similar manner to the monkeys in the image, sitting on rocks and surrounded by trees. The Santani Workshop in Russia is known for creating intricate porcelain dolls, and the \"Inari Foxes\" collection is one of their popular lines.\n",
      "27\n",
      "test_acm/images_test_acm/27.jpg\n",
      "context 1: The image shows a person wearing a Promobot robot suit, which is a type of humanoid robot designed to mimic human movements and gestures. The robot suit is equipped with a head and hands that have hyper-realistic skin, giving it a lifelike appearance. The person wearing the suit is holding a cell phone in their hand, and their other hand is placed on the robot's head, possibly adjusting or operating it. The scene takes place in a room with a dining table in the background.\n",
      "context 2: The image shows a person attaching \"skin\" to the head of a humanoid robot. The robot is designed to resemble a human and is being prepared for an event. The person is carefully placing the \"skin\" over the robot's head, ensuring that it covers the entire head and face area. The process appears to be delicate and requires precision to achieve the desired outcome. Once the \"skin\" is in place, the robot will have a more lifelike appearance, making it suitable for various events or interactions with people.\n",
      "28\n",
      "test_acm/images_test_acm/28.jpg\n",
      "context 1: On Tuesday, a group of police officers patrolled the school where more than 300 children were kidnapped in Katsina state, northern Nigeria. The officers were seen walking around the area, likely ensuring the safety and security of the children and the school premises. The incident has sparked outrage and concern among the community and the public, and the police presence at the school is an effort to prevent any further incidents and to bring the perpetrators to justice.\n",
      "context 2: The image shows two police officers patrolling the Government Science school in Kankara, Nigeria, where students were abducted on December 15, 2020. The officers are walking through the school's courtyard, which is surrounded by trees. There are also several people in the scene, some of whom may be students or bystanders. The presence of the police officers indicates that security measures are in place to ensure the safety of the students and maintain order in the area.\n",
      "29\n",
      "test_acm/images_test_acm/29.jpg\n",
      "context 1: The federal gun law passed in September 2016 that prevents people from practicing \"open carry\" in all 50 states refers to the Open Carry Law, which was enacted in Texas in 1995. This law allows individuals to openly carry handguns in public places, as long as they have a valid license to carry a concealed handgun. The Open Carry Law has been the subject of controversy and debate, with some arguing that it promotes safety and personal responsibility, while others believe it can lead to an increase in accidental shootings and confrontations. The federal law, which overrides state laws, aims to standardize gun laws across the country and address concerns related to open carry.\n",
      "context 2: The image shows an open carry advocate walking down the street in Austin, Texas, with a rifle strapped to their back. The man is wearing a leather jacket and is surrounded by a crowd of people. Some of the individuals in the crowd are carrying handbags, while others are simply walking alongside the open carry advocate. The scene depicts a lively and diverse urban environment where people engage in various activities and interact with one another.\n",
      "30\n",
      "test_acm/images_test_acm/30.jpg\n",
      "context 1: In the image, a lobsterman is holding up an extremely rare purple lobster in his hand. This is an unusual sight, as purple lobsters are not commonly found in the wild. The coloration of the lobster is due to a genetic condition called xanthochromism, which causes the pigmentation to be primarily purple instead of the usual red or orange. The lobsterman's catch has attracted attention, as it is an opportunity to study and learn more about the rare species.\n",
      "context 2: The image is a fake or Photoshopped picture, featuring two purple lobsters with one having a purple carapace and the other having a purple body. The colors are not naturally occurring in lobsters.\n",
      "31\n",
      "test_acm/images_test_acm/31.jpg\n",
      "context 1: According to a recent article in The New York Times, the ZIP code 11220, which is located in the Brownsville neighborhood of Brooklyn, has the highest death rate of any ZIP code in New York City. The high mortality rate in this area is attributed to a combination of factors, including poverty, crime, and poor health outcomes. The Brownsville neighborhood has a high concentration of auto repair shops, which may contribute to air pollution and other environmental concerns. Additionally, the neighborhood has a high rate of unemployment and limited access to healthcare, which can exacerbate the challenges faced by its residents.\n",
      "context 2: In the image, a man is walking past a store with a large display of tires. He is wearing a face mask, which suggests that he is taking precautions to protect himself from the COVID-19 virus. The store has a variety of tires, including some stacked up in the background. There are also a few other people in the scene, but they are not as prominent as the man wearing the face mask. The man appears to be walking past the store, possibly passing by the display of tires on the sidewalk.\n",
      "32\n",
      "test_acm/images_test_acm/32.jpg\n",
      "context 1: In the image, U.S. Secretary of State Mike Pompeo is smiling and standing inside a mosque in Egypt's new administrative capital, surrounded by a group of people. The mosque features a large dome and a high ceiling, creating an impressive and grand atmosphere. The Secretary of State appears to be enjoying his visit and engaging with the people around him, highlighting the importance of cultural understanding and diplomacy in international relations.\n",
      "context 2: In the image, U.S. Secretary of State Mike Pompeo is standing in the middle of a group of people, smiling and engaging with them. He is surrounded by a diverse group of individuals, some of whom are wearing ties, indicating a formal or professional setting. The group appears to be gathered for a special occasion or event, possibly a tour or a diplomatic meeting. The Secretary of State is actively participating in the interaction, suggesting a positive and friendly atmosphere.\n",
      "33\n",
      "test_acm/images_test_acm/33.jpg\n",
      "context 1: This is a fake news headline. The image shows Will Smith and Jaden Smith posing for a picture, but the headline claiming that they died in a crash is completely false.\n",
      "context 2: The image and text were a hoax, as neither Will Smith nor his son Jaden Smith had died or been seriously injured in an automobile accident. The post was intended to spread false information and cause panic or concern among the readers. It is important to verify the authenticity of information shared on social media platforms to avoid spreading misinformation.\n",
      "34\n",
      "test_acm/images_test_acm/34.jpg\n",
      "context 1: In the image, a man is seen diving into the water near Canary Wharf, London. He is wearing a red shirt and is surrounded by several other people who are also in the water. The scene appears to be a lively and enjoyable moment, possibly involving a group of friends or people taking part in a water-based activity. The presence of boats in the background further supports the idea that this is a recreational area or a popular spot for water-based activities.\n",
      "context 2: In the image, a man is seen diving into the water in the London Docklands while two other men are in inflatable boats nearby, watching the action. The man in the inflatable boat on the left is holding a surfboard, and the man in the inflatable boat on the right is wearing a backpack. The scene appears to be a fun and exciting outdoor activity, possibly involving water sports or adventure games. The presence of boats and the urban setting create a unique and dynamic atmosphere for the participants and onlookers alike.\n",
      "35\n",
      "test_acm/images_test_acm/35.jpg\n",
      "context 1: Traffic on the railway between Ivory Coast's biggest city, Abidjan, and Ouagadougou, the capital of Burkina Faso, was halted on Friday after a landslide. The landslide occurred near the town of Korhogo, which is approximately 200 kilometers northeast of Abidjan. The affected railway line is a vital transportation link between the two countries, and the landslide has caused significant disruptions to the transportation of people and goods. The cause of the landslide is not known, but it is likely related to the ongoing civil unrest in the region. The situation is being closely monitored by local authorities and railway operators, who are working to restore normal train services as soon as possible.\n",
      "context 2: The image shows a suspended railway track at the site of a landslide that occurred the day before, near Abidjan, Ivory Coast. The landslide has caused the tracks to be disconnected and dangling in the air. The scene is quite dramatic, with the disconnected train tracks hanging over a hillside and surrounded by a lush green forest. The landslide has also affected the surrounding area, with trees and debris scattered across the landscape. The incident has resulted in 13 fatalities and has left the railway line in a precarious state, requiring immediate attention and repair efforts to restore connectivity and safety.\n",
      "36\n",
      "test_acm/images_test_acm/36.jpg\n",
      "context 1: The Annabelle doll is a well-known character in the horror genre, often associated with the supernatural and paranormal activities. The doll is said to have a sinister presence and is believed to be possessed with evil spirits. The doll is displayed in the Warren's Occult Museum in Connecticut, which is known for its collection of haunted and mysterious objects. However, in the image, the doll is shown escaping from the museum, which is an unconventional and unexpected turn of events for this character. The doll's presence in the museum and its escape adds a sense of mystery and intrigue to the scene.\n",
      "context 2: The image shows a doll with red hair, sitting on a wooden chair, and looking to the side. It is not a real doll, but rather a representation or a prop used in a horror movie. The doll is not alive and did not escape. The quote from sources is likely referring to the fictional character Annabelle, who is a famous character from the horror movie \"The Conjuring\" and is not a real person or doll.\n",
      "37\n",
      "test_acm/images_test_acm/37.jpg\n",
      "context 1: Yes, the towering snow walls are located in Massachusetts. The image shows a snow-covered mountain with a large snow wall, and people walking on a path alongside the snow wall. This suggests that the location is likely in a region where heavy snowfall and snow accumulation are common, such as the Northeast United States.\n",
      "context 2: Tateyama Kurobe is a snow-covered mountain pass in Japan that attracts many tourists during the winter months. The snow-covered road and tunnel provide a unique and picturesque experience for visitors. In the image, a large group of people is walking along the snow-covered road, likely admiring the beautiful scenery and enjoying the winter atmosphere. The tunnel, which is also covered in snow, adds to the charm of the location. The presence of numerous people in the scene suggests that it is a popular destination for tourists and locals alike.\n",
      "38\n",
      "test_acm/images_test_acm/38.png\n",
      "context 1: When setting the date on an Apple device to 1 January 1970, a retro-themed Easter egg appears on the screen. This Easter egg displays a message that reads \"Today's date is January 1, 1970. Your iPhone remembers this date and time as the first date the device was ever set up. This is a reference to the first iPhone ever sold, which was the iPhone 1 on January 9, 2007. The Easter egg also displays a retro clock, reminiscent of the clocks found on early iPhone models. This feature is a fun and nostalgic nod to the history of the Apple device and its development.\n",
      "context 2: If you want to block a date on your iPhone, you can set it to January 1, 1970. However, this date has no significance and is not commonly used. It is not recommended to set your date to this specific date, as it may cause confusion or inconvenience in the future. It is better to set a date that has personal or historical significance to you.\n",
      "39\n",
      "test_acm/images_test_acm/39.jpg\n",
      "context 1: In November 2018, it was reported that 53,000 dead people were found to be included on Florida's voter rolls. This discovery led to an investigation by the Florida Department of State to remove the ineligible voters from the rolls. The state of Florida uses the Help America Vote Act's (HAVA) motor voter law to maintain its voter registration list, which includes the process of matching voter records with death records to identify deceased individuals. The investigation ensures that the state's voter rolls are accurate and up-to-date, preventing voter fraud and maintaining the integrity of the electoral process.\n",
      "context 2: The social media posts linked to an article published by Fox News in 2012, not a recent article about the Florida recount in November 2018. The article from 2012 discusses the impact of a new voter-related law in Florida, not the recount process that happened in 2018.\n",
      "40\n",
      "test_acm/images_test_acm/40.jpg\n",
      "context 1: It is not possible for me to determine if Snopes.com intentionally ignored the reports or if they simply did not cover the story in their articles. However, it is important to note that Snopes.com is a fact-checking website that aims to provide accurate information by investigating the veracity of claims made in various media sources. They would not ignore a significant event like a bust of a child trafficking ring without thoroughly researching and verifying the facts. It is possible that they did not cover the story due to a lack of reliable sources or because the information presented in the reports was not substantiated.\n",
      "context 2: The image is a black and white photo of a person's hands tied together with rope. The person's hands are positioned close to each other, with the rope wrapped around their wrists. The hands appear to be tied in a secure manner, with the rope running through the center of the person's hands. The lack of color in the photo emphasizes the simplicity and form of the person's hands and the rope.\n",
      "41\n",
      "test_acm/images_test_acm/41.jpg\n",
      "context 1: The image shows a large group of people gathered around an erupting volcano in Iceland. The volcano is spewing out lava and ash, creating an impressive and potentially dangerous scene. The crowd consists of people from various age groups and backgrounds, all of whom have come together to witness this unique natural event. Some of the people are wearing backpacks, indicating that they might be tourists or prepared for a day outdoors. The presence of a large number of people near the volcano demonstrates the fascination and curiosity that people have towards natural phenomena and the appeal of experiencing such a rare and captivating event.\n",
      "context 2: A volcano has erupted in Iceland, spewing lava and ash into the air, creating a spectacular sight for the gathered crowd of people.\n",
      "42\n",
      "test_acm/images_test_acm/42.jpg\n",
      "context 1: The image features a woman wearing a pink top, practicing yoga on a boat. She is in a yoga pose, surrounded by various items on the boat. The boat appears to be a narrowboat, which is a type of boat designed for use on narrow canals and rivers. There are several chairs, a dining table, a potted plant, and a bottle visible in the scene. The woman seems to be enjoying her yoga session in this unique setting.\n",
      "context 2: The image features a woman in a yoga pose on a boat, which appears to be a narrowboat. She is practicing her yoga in the living area of the boat, which includes a couch and a chair. The woman seems to be enjoying her time on the boat and taking advantage of the available space to engage in her yoga practice.\n",
      "43\n",
      "test_acm/images_test_acm/43.jpg\n",
      "context 1: The image depicts a group of people, including men and women, sleeping on the floor in a crowded room. They are resting on mats or pallets, with some of them appearing to be in a jail cell. The room is dimly lit, and the individuals seem to be in various stages of sleep.There are several bottles scattered throughout the room, possibly containing water or other beverages for the inmates. The overall atmosphere suggests a shared living space where people are resting and recharging before or after their activities.\n",
      "context 2: The image shows a group of people, including detainees, sleeping in a jail cell. The cell is located near a small grotto of Mary, which is a Catholic shrine. The detainees are resting on the floor, with some of them lying on mats. The scene depicts a humble and simple living environment, with the inmates sharing the space in a close and communal manner.\n",
      "44\n",
      "test_acm/images_test_acm/44.jpg\n",
      "context 1: The National Cancer Institute (NCI) is a government agency and does not \"admit\" or \"make admissions\" in the same way a person would. The NCI's website and publications do acknowledge the potential benefits of cannabis-derived compounds in cancer treatment, but they emphasize that further research is needed to confirm these benefits and establish safe and effective treatment options. The NCI's position is based on scientific evidence and is not an \"admission\" of any specific claim.\n",
      "context 2: The image shows a prescription bottle, a stethoscope, and a marijuana plant. However, there is no evidence in the image or any other information provided to support the claim that marijuana can be used as a viable treatment for cancer. This claim is subjective and cannot be verified as true.\n",
      "45\n",
      "test_acm/images_test_acm/45.jpg\n",
      "context 1: The image shows a metro train in the city of Spijkenisse, in the Netherlands, resting precariously on an art installation of a whale after crashing through a barrier at the end of the tracks. The train appears to be tilted, and the whale sculpture seems to be holding the train up. There are several people standing around the scene, observing the unusual situation. Some of them are closer to the train, while others are further away. The presence of multiple people suggests that this is an interesting and noteworthy event in the city.\n",
      "context 2: The image features a metro train resting on top of a whale sculpture, which appears to be an art installation. The train is positioned on the back of the whale, giving the impression of the train riding on the ocean creature. There are several people standing around the scene, observing the unique installation. Some of them are closer to the train, while others are further away, taking in the entire scene. The presence of the people suggests that this art installation has drawn their attention and interest.\n",
      "46\n",
      "test_acm/images_test_acm/46.jpg\n",
      "context 1: The image shows a large hole in the ground, surrounded by grass and trees. It is not possible to determine the specific context or story behind the hole based solely on the visual information provided.\n",
      "context 2: The image of the man digging a tunnel in the ground turned out to be a hoax. It was a fake image that had been digitally altered to create the illusion of a man digging a hole in the ground. Thousands of people were fooled by this fake image, sharing it on social media and believing it to be a real scene. This highlights the importance of verifying the authenticity of shared content and being cautious when consuming information online.\n",
      "47\n",
      "test_acm/images_test_acm/47.png\n",
      "context 1: The image shows a man lying on a stretcher in an emergency situation, with a crowd of people gathered around him. The scene appears to be a combination of two different photos, one showing the injured man and the other showing an emergency vehicle and people attending to him. The man on the stretcher is wearing a leg brace, which suggests that he has sustained significant injuries. The presence of emergency personnel and the ambulance indicates that the man has been attended to and is receiving medical assistance. The exact cause of the injuries and the context of the situation are not clear from the image alone, but it is evident that the man has experienced an accident or an incident that has resulted in his injuries.\n",
      "context 2: The image shows a person lying on the ground with an injured leg, surrounded by emergency personnel. The scene appears to be a busy street, as there are several cars and a truck in the vicinity. The photograph of the ruptured scuba tank has been circulating since at least 2008, and the image of the ambulance was taken in 2015 after an assault in Calgary.\n",
      "48\n",
      "test_acm/images_test_acm/48.jpg\n",
      "context 1: The image depicts a cow standing on the sidewalk in front of a tailor shop in a city street. The cow appears to be curiously looking into the shop, possibly attracted by the activity inside. There are several people around the cow, with some standing close to the cow and others further away. In addition to the cow, there are two motorcycles parked nearby, one closer to the shop and the other further away. A bicycle can also be seen parked close to the motorcycles. The scene captures the unique blend of rural and urban elements in the city.\n",
      "context 2: The image depicts a sacred cow standing in the middle of a street in India. The cow is surrounded by various objects, including a motorcycle, a bicycle, and a few chairs. There are also people in the scene, with one person standing close to the cow and another person further away. The presence of the sacred cow in the street indicates that it might be a holy animal, and people might be cautious to avoid disturbing it. The scene captures the unique atmosphere of the Indian street, where traditional and modern elements coexist.\n",
      "49\n",
      "test_acm/images_test_acm/49.jpg\n",
      "context 1: This statement is false and misleading. The Centers for Disease Control and Prevention (CDC) and the Federal Bureau of Investigation (FBI) are two separate agencies with distinct roles and responsibilities. The CDC is a public health agency responsible for protecting the health and well-being of Americans, while the FBI is a law enforcement agency responsible for investigating criminal activities. The two agencies do not typically work together on the same projects or share data related to health and criminal investigations. Additionally, there is no evidence to support the claim that the CDC is involved in any link between vaccines and autism. Vaccines are extensively researched and proven to be safe and effective in preventing diseases.\n",
      "context 2: This image shows the Federal Bureau of Investigation (FBI) headquarters building, which is a large blue and white building located in downtown Atlanta, Georgia. However, the claims that the FBI \"raided\" the CDC in the middle of the night for data on vaccines and autism, as purported by the hoax purveyor, are false. The Centers for Disease Control and Prevention (CDC) is a separate agency from the FBI, and they do not share data or work together in this manner. The image and the claims made by the hoax purveyor do not align, and it is important to fact-check and verify the accuracy of information before sharing it.\n",
      "50\n",
      "test_acm/images_test_acm/50.jpg\n",
      "context 1: James Maina Mwangi, who once claimed to be Africa's most stylish man, is seen wearing a purple hat and a suit with a tie. He is also wearing a mask, possibly to protect himself from the COVID-19 pandemic. The image shows him posing in front of a rack of clothing, which includes ties and a suit jacket. The outfit he is wearing is a mix of formal and casual elements, with the hat and suit jacket adding a touch of sophistication to his overall appearance.\n",
      "context 2: The image features a man wearing a purple hat, jacket, and tie, along with a pair of glasses. He is standing next to a rack of clothing, which includes several suits in various colors, such as green, yellow, and red. The man is also wearing a mask, possibly for protection or as a fashion statement. The combination of his unique outfit and the colorful suits in the background creates an interesting and eye-catching scene.\n",
      "51\n",
      "test_acm/images_test_acm/51.jpg\n",
      "context 1: The British Parliament's famous clock tower, Big Ben, is undergoing renovation work.\n",
      "context 2: In the image, a group of tourists is taking pictures of a large clock tower using their cell phones. There are at least three people visible in the scene, with their cell phones being held up to capture the moment. The clock tower is a prominent landmark, and the tourists are likely capturing memories of their visit to the location.\n",
      "52\n",
      "test_acm/images_test_acm/52.jpg\n",
      "context 1: In the image, Lex Scott Davis and Trevor Jackson are portraying the main characters in the movie \"Superfly.\" They are standing next to each other, engaged in a conversation. Both actors are dressed in stylish black outfits, with Davis wearing a black dress and Jackson wearing a black suit. The scene takes place in a room with a dining table and chairs, and there are several wine glasses and cups placed around the table. The overall atmosphere of the image suggests a sophisticated and elegant setting, which is fitting for the characters' social gathering.\n",
      "context 2: In the image, there are two people standing next to each other, with one of them wearing a black dress and the other dressed in a suit. They are both staring at the camera. The man in the suit is wearing a tie, and the woman in the black dress is wearing a necklace. They appear to be engaged in a conversation or a photoshoot.\n",
      "53\n",
      "test_acm/images_test_acm/53.png\n",
      "context 1: The image features a photograph of a genuine fossil of a megalodon tooth embedded in a whale bone. The tooth is large and prominent, with the bone beneath it providing a clear context for the size and scale of the megalodon. The scene is displayed on a table, drawing attention to the unique and fascinating nature of the fossil.\n",
      "context 2: The image features a large rock with a tooth carved into it, which is a unique and interesting piece of art. The tooth is likely a replica or a carving of a megalodon tooth, a prehistoric shark. In the same scene, there is a whale bone, which is a real bone from a whale. The two artifacts were not discovered at the same time, in the same location, or in this particular arrangement. The rock with the carved tooth and the whale bone are displayed together, creating an intriguing contrast between the two distinct pieces of art.\n",
      "54\n",
      "test_acm/images_test_acm/54.jpg\n",
      "context 1: In the image, British Prime Minister Theresa May is standing at a podium, giving a speech to the media outside of 10 Downing Street. She is wearing a blue dress and appears to be addressing an important issue or event. The scene is set at night, with the streetlights illuminating the area. There are several people in the scene, including those standing near the podium and others further away, all listening to the Prime Minister's speech. A clock can be seen in the background, indicating the time of the event.\n",
      "context 2: The image shows Theresa May, the former British Prime Minister, delivering a statement to the media in front of a building. She is standing in front of a podium, addressing the reporters and cameramen present. The scene suggests that she is addressing the media after a vote of no confidence in her government, where she managed to remain in power despite the challenge. In her statement, she emphasizes the importance of working together and consulting with politicians from different parties to find a solution to the ongoing Brexit issue.\n",
      "55\n",
      "test_acm/images_test_acm/55.jpg\n",
      "context 1: The image shows a pile of trash, including clothes, blankets, and personal belongings, left behind by the migrant caravan in a grassy field.\n",
      "context 2: The image shows a field with clothes, blankets, and personal belongings scattered around, but it is not related to the caravan of refugees from Honduras. The photograph was taken in a park, and the scene depicted is not related to the recent events in October 2018. The presence of a backpack and a bottle in the image does not confirm any connection to the caravan either. The image is likely an older photograph that shows discarded items in a park setting.\n",
      "56\n",
      "test_acm/images_test_acm/56.jpg\n",
      "context 1: The image shows a giraffe crossing a road in a wildlife sanctuary, with a car waiting patiently on the other side. The giraffe is walking across the road, and there are several people in the scene, likely observing the giraffe's crossing. The car is positioned on the left side of the road, and the giraffe is walking towards the right side. The scene captures the unique moment of a giraffe navigating its natural habitat while sharing the road with vehicles, emphasizing the importance of preserving wildlife corridors and respecting the animals' space.\n",
      "context 2: In the image, a giraffe is crossing a road that is lined with electric fences. There are several cars and a truck on the road, with one car positioned behind the giraffe and another car further ahead. The giraffe appears to be walking confidently across the road, while the vehicles seem to be waiting for the giraffe to clear the way. The presence of electric fences along the road suggests that the area might be a wildlife reserve or a protected habitat for the giraffe, ensuring the safety of the animal while allowing vehicles to pass through.\n",
      "57\n",
      "test_acm/images_test_acm/57.jpg\n",
      "context 1: The image features a mural painted in 1994 at Denver International Airport that depicts people from various countries wearing surgical masks. The mural is a large painting that covers a wall, showcasing a diverse group of individuals from different parts of the world. The masks symbolize unity and solidarity, as they are worn by people from various countries to represent their shared humanity and connection to one another. The mural serves as a powerful visual representation of the importance of global cooperation and understanding.\n",
      "context 2: The image shows a painting featuring a group of women wearing masks, with each woman representing a different country. The painting is a creative and artistic representation of unity and solidarity in the face of global challenges.\n",
      "58\n",
      "test_acm/images_test_acm/58.jpg\n",
      "context 1: On Wednesday, cars wait patiently for a giraffe to cross the road in Kenya's Kimana Sanctuary.\n",
      "context 2: In the image, a giraffe is crossing a road that is lined with electric fences. There are several cars and a truck on the road, with one car positioned behind the giraffe and others scattered along the road. The giraffe appears to be walking confidently across the road, while the vehicles seem to be waiting for the giraffe to clear the way. The presence of electric fences along the road suggests that this area might be a wildlife reserve or a protected habitat for the giraffe, ensuring the safety of the animal while allowing vehicles to pass through.\n",
      "59\n",
      "test_acm/images_test_acm/59.jpg\n",
      "context 1: The image features a sheep standing inside a bus shelter on a road, seemingly curious about its surroundings. The shelter is located near a grassy hill, and the scene appears to be in a rural area. There are a few cars parked nearby, indicating that the location is accessible by vehicles. The sheep seems to be looking at something or someone outside the shelter, drawing attention to the unusual sight of a sheep inside a bus shelter.\n",
      "context 2: In the image, a sheep is sitting inside a bus shelter on a road, drawing attention due to the unusual sight. The shelter is a small, white structure with a glass window, providing shelter for the sheep. The scene is set in a rural area, with a hill visible in the background. The presence of the sheep in the bus shelter adds a unique and amusing twist to the typical scene of a bus shelter being used for sheltering people rather than animals.\n",
      "60\n",
      "test_acm/images_test_acm/60.png\n",
      "context 1: The image shows a motorist lying in the middle of the road, with a car nearby. However, the story about sex traffickers tricking motorists by lying in the road is not accurate. This information is a part of a fake news story that has been circulating on the internet. The image itself is not related to the fake news story, and the motorist lying in the road is not part of the traffickers' scheme. The image shows a real-life situation where a person is lying in the road, which can be dangerous for both the person and the passing vehicles.\n",
      "context 2: Upon reviewing the November and December 2019 Facebook posts, it was found that the photographs included in these posts do not show a specific incident of attempted sex trafficking. The posts primarily consist of images of dead animals on the road, with no clear connection to the topic of sex trafficking.\n",
      "61\n",
      "test_acm/images_test_acm/61.png\n",
      "context 1: The image shows a large snake swimming across a river in Brazil.\n",
      "context 2: The image is a distorted video that has been altered to make the snake appear much larger than it actually is. The snake is not as big as it appears in the image.\n",
      "62\n",
      "test_acm/images_test_acm/62.jpg\n",
      "context 1: The image depicts a rescue operation at the site of a train accident on the Great Belt Bridge in Nyborg, Denmark. Several rescue workers are gathered around the wreckage, which consists of a train car and a helicopter. The workers are wearing safety gear and appear to be assessing the situation and coordinating their efforts to recover any injured passengers or retrieve any necessary equipment. The presence of the helicopter suggests that it might be used for aerial support or transportation during the rescue operation.\n",
      "context 2: The image shows a passenger train that has been struck by a cargo container in Denmark early Wednesday. The train is now sitting on the tracks, and there are several people standing around the train, possibly inspecting the damage or working to clear the cargo container from the train. The scene also includes a truck nearby, which might be used for transporting the cargo container or assisting in the clean-up process.\n",
      "63\n",
      "test_acm/images_test_acm/63.jpg\n",
      "context 1: The image depicts a rescue operation at the site of a train accident on the Great Belt Bridge in Nyborg, Denmark. Several rescue workers are present, wearing safety gear and working together to address the situation. There are two main trains involved in the accident, one of which is on the bridge, while the other is located on the ground. The rescue workers are standing near the train on the bridge, likely assessing the damage and planning their next steps. In addition to the rescue workers, there are also two trucks visible in the scene, one of which is positioned closer to the train on the ground, while the other is near the train on the bridge. The presence of the trucks suggests that they may be involved in the rescue effort or providing support to the workers.\n",
      "context 2: The image shows emergency crews working at the site of a train accident that occurred in Nyborg, Denmark. The accident involved a train and a truck, resulting in at least six fatalities. The scene depicts a rescue operation, with emergency workers wearing reflective vests and working together to address the situation. The train has been significantly damaged, and it is unclear whether it was involved in an accident with the truck or if the train itself was the cause of the incident. The rescue team is focused on providing assistance and ensuring the safety of those affected by the tragedy.\n",
      "64\n",
      "test_acm/images_test_acm/64.jpg\n",
      "context 1: The image shows Indian paramilitary troops in Srinagar, Kashmir, with a truck and a bus in the background. The presence of old equipment among the troops indicates that the Indian military might be facing challenges in terms of modernization and technology. It is important to note that the Indian government has been facing criticism for its handling of the Kashmir conflict and the lack of progress in providing better resources and support to the troops. The presence of old equipment among the troops may be one of the reasons for these criticisms.\n",
      "context 2: The image shows a group of armed soldiers in a city street, with some of them riding on a truck. The presence of the soldiers indicates that the situation in the city might be tense or undergoing military operations. The escalation of shelling and gunbattles in Kashmir has raised concerns about the safety of the residents, and the city is bracing for the worst as the conflict continues. The government and the military must prioritize the protection of civilians and ensure that they are not caught in the crossfire during these operations.\n",
      "65\n",
      "test_acm/images_test_acm/65.jpg\n",
      "context 1: The image shows a group of policemen standing in formation, wearing riot gear and holding batons, as they guard the entrance to the state secretariat. This presence of the police is likely to prevent any potential protests or disturbances that may arise due to the recent news about two women of menstruating age entering the Sabarimala temple. The policemen are prepared to maintain order and ensure the safety of the public and the government building.\n",
      "context 2: In the Indian state of Tamil Nadu, a group of 10 women was barred from entering an ancient temple by police officers, despite a court order allowing them to pray. The incident occurred on August 26, 2021, when the women tried to enter the temple, but were stopped by the police. The women were protesting a ban on entry for women of menstruating age, which had been imposed by the temple management. The situation escalated, and the police used batons to disperse the crowd. The incident sparked outrage and condemnation from various quarters, including the public, political leaders, and human rights activists. The state government has since ordered an inquiry into the incident and vowed to take appropriate action.\n",
      "66\n",
      "test_acm/images_test_acm/66.jpg\n",
      "context 1: In the image, a man is standing in a field of corn, holding a long stick to scare away a swarm of locusts. The locusts are swarming across the field, and the man is taking action to protect his crops from the pests. This scene highlights the challenges farmers face in certain regions, where locust swarms can cause significant damage to their crops, potentially leading to economic losses and food insecurity. The man's action demonstrates his determination to protect his livelihood and maintain the productivity of his land.\n",
      "context 2: In the image, a man is standing in a field of corn, holding a long stick to chase away locusts. He is trying to protect his crops from the pests, which can cause significant damage to plants if left unchecked. The man's action demonstrates his determination to maintain the health and productivity of his crops.\n",
      "67\n",
      "test_acm/images_test_acm/67.jpg\n",
      "context 1: In the image, a woman is holding a red paintbrush and painting the helmet of a riot police officer who is standing behind her. The scene takes place during a protest, possibly against gender and police violence, as indicated by the context. The riot police officer is wearing a helmet and a uniform, while the woman is using the paintbrush to create a bold statement by transforming the police officer's uniform into a symbol of resistance and solidarity.\n",
      "context 2: The image depicts a protest in Mexico City, where a group of people, including a riot police officer, are gathered. A protester is seen painting the visor of the riot police officer with a red substance, possibly to symbolize bloodshed or opposition to the government. The riot police officer is wearing a helmet and a uniform, and is standing among the crowd. There are several other people in the scene, some of whom are also wearing helmets, likely part of the riot police force. The protest appears to be taking place in an urban setting, with buildings and streets visible in the background.\n",
      "68\n",
      "test_acm/images_test_acm/68.jpg\n",
      "context 1: This is a false statement as President Obama did not pass any law related to grandparents and weekend visits. The image shows two older people looking at a baby, but it has no connection to any law or legislation passed by President Obama. The statement is a joke and should not be taken seriously.\n",
      "context 2: The reports claiming that President Obama had passed a law requiring grandparents to pick up their grandchildren every weekend are false and misleading. These claims are not based on any actual legislation or policy from the Obama administration. The story is likely a hoax or a fabricated news report designed to mislead and deceive readers. It is important to verify the authenticity of news sources and not rely solely on headlines or social media shares to determine the accuracy of information presented.\n",
      "69\n",
      "test_acm/images_test_acm/69.jpg\n",
      "context 1: The image shows a woman walking past a mural on a building, which is designed to remind Abidjan's residents of anti-coronavirus hygiene measures. The mural features a painting of a man wearing a surgical mask and glasses, with a message in French. The woman is also wearing a surgical mask as she walks by the mural, demonstrating the city's commitment to promoting and maintaining hygiene in the face of the pandemic.\n",
      "context 2: The image features a woman walking down the street while wearing a mask. She is passing by a large mural on the side of a building, which depicts a person wearing a mask. The mural is vibrant and eye-catching, drawing attention to the masked figure as a prominent element of the scene. The woman's presence in the scene adds a sense of realism, as she navigates through the urban environment with the same level of caution as the person in the mural.\n",
      "70\n",
      "test_acm/images_test_acm/70.jpg\n",
      "context 1: I'm sorry, but that information is incorrect. Actor Jaden Smith did not commit suicide in July 2016. The image shows two men sitting at a table, not an actor. Could you please provide more accurate information about the topic you want to discuss?\n",
      "context 2: The image shows Will Smith and his son Jaden Smith sitting together on a couch, laughing and enjoying each other's company. There is no indication of any suicide or any other negative or harmful content in the image. The hoax article spreading this false information is to be avoided and disregarded.\n",
      "71\n",
      "test_acm/images_test_acm/71.png\n",
      "context 1: The image depicts a woman in Indonesia, in the town of Toraja, leaving her grave after being dead for three years. She is surrounded by a group of people, including a man in a blue shirt who is assisting her. The scene takes place in a dirt field, and the woman is dressed in traditional Toraja clothing. The people in the image appear to be helping her in her transition from the grave, possibly as part of a cultural or spiritual practice.\n",
      "context 2: The photograph does not show an actual zombie. Instead, it shows a person in a costume, likely for a party or event, with a fake body part hanging from their face.\n",
      "72\n",
      "test_acm/images_test_acm/72.jpg\n",
      "context 1: In the image, Felix Tshisekedi, a largely untested candidate, is seen standing in front of a crowd of people. He is wearing a white shirt and a tie, and appears to be waving to the crowd. The people in the crowd are gathered around him, and some of them are holding cell phones. The scene suggests that Tshisekedi might be addressing the crowd or celebrating his election results, as he received more than seven million votes, according to the Electoral Commission.\n",
      "context 2: In the image, Felix Tshisekedi, the newly elected president of the Democratic Republic of Congo, is standing in front of a crowd of people. He is wearing a white shirt and a tie, and he appears to be smiling. The people in the crowd are celebrating his victory, and they are holding up their cell phones, possibly to capture the moment or share the news with others. The atmosphere seems joyful and triumphant, as the people gather to support and honor their new leader.\n",
      "73\n",
      "test_acm/images_test_acm/73.png\n",
      "context 1: The image shows a group of police officers in New York City wearing \"I Can Breathe\" shirts, which is a reference to the slogan associated with the Black Lives Matter movement. The shirts are mocking the death of George Floyd, a black man who was killed by police officers in Minnesota in May 2015. The officers' actions have sparked controversy and criticism, as it is considered disrespectful to the memory of Floyd and the ongoing fight against police brutality and racial injustice.\n",
      "context 2: The image shows a group of police officers wearing t-shirts that read \"I Can't Breathe\" and \"I Can Breathe NYC Police.\" These shirts are a reference to the death of Eric Garner, who died after being placed in a chokehold by a New York City police officer during an arrest in 2014. The phrase \"I Can't Breathe\" became a rallying cry for protesters and the public, calling attention to the incident and the broader issue of police brutality and racial profiling. The police officers' shirts are a symbol of solidarity and a reminder of the events surrounding Eric Garner's death.\n",
      "74\n",
      "test_acm/images_test_acm/74.jpg\n",
      "context 1: Ten years on, Japan is commemorating the victims of the Great East Japan Earthquake and the Fukushima Daiichi nuclear disaster that occurred on March 11, 2011. The anniversary events are being held in various locations across the country, including Tokyo, where a large candlelit vigil is taking place in front of the Japanese Diet building. Thousands of people have gathered to pay their respects and remember the lives lost and the devastation caused by these tragedies. The commemorations also serve as a reminder of the resilience and strength of the Japanese people in the face of adversity.\n",
      "context 2: The image shows a large group of people gathered in a field, with rows of lit paper lanterns as a memorial for the victims of the earthquake and tsunami disaster that occurred in Japan on March 11, 2011. The people are sitting and standing in the field, with some of them holding hands, creating a sense of unity and solidarity. The field is filled with numerous lit lanterns, creating a visually striking and emotional display. The scene captures the spirit of remembrance and support for those affected by the disaster.\n",
      "75\n",
      "test_acm/images_test_acm/75.png\n",
      "context 1: The image displays a graphic that shows several concepts for the dress uniforms of the U.S. Space Force, which is a newly established branch of the military. The uniforms are designed to reflect the unique nature of space operations and are being officially considered by the Space Force. The image features a variety of uniforms, including different types of jackets, ties, and hats. Some of the uniforms also include medals, indicating the accomplishments and service of the individuals wearing them. The graphic showcases a thoughtful design process that aims to create a distinct and professional appearance for the members of the U.S. Space Force.\n",
      "context 2: The image being shared on social media is not an official U.S. Space Force uniform design concept. It is a graphic that has been altered and manipulated, and the person who shared it may have added or changed elements to create a visually appealing or humorous image. It is important to note that the U.S. Space Force is still in the process of establishing its uniform design, and any unofficial designs or images circulating on social media should be considered speculative or fan-made.\n",
      "76\n",
      "test_acm/images_test_acm/76.jpg\n",
      "context 1: The image shows Goldie Hawn and Kurt Russell, both wearing Donald Trump t-shirts, standing next to each other. They are posing for a picture, and it appears to be a fun and casual moment between the two famous actors.\n",
      "context 2: The image of actors Goldie Hawn and Kurt Russell wearing Donald Trump campaign shirts is a digital fabrication. It is not an actual photograph of the two actors, but rather a manipulated image created to depict them as supporters of the Donald Trump campaign. This image has been shared on social media and other platforms, but it is not an accurate representation of the actors' political views or actions.\n",
      "77\n",
      "test_acm/images_test_acm/77.jpg\n",
      "context 1: In the image, two men are working together to finish a wooden casket in a workshop. They are both focused on their task, ensuring the casket is made with care and attention to detail. The workshop is filled with various wooden caskets, some of which are already completed, while others are in different stages of the manufacturing process. The presence of multiple caskets in the workshop suggests that the business is actively engaged in providing funeral products to the community.\n",
      "context 2: The image depicts a man in a workshop in Mbare, Harare, Zimbabwe, handling a large wooden box. The man is wearing a blue shirt and is surrounded by several other wooden boxes and a car. The workshop appears to be a place where coffins are made, as indicated by the presence of these large wooden boxes. The man is likely involved in the process of creating or handling these coffins, possibly working on a project or preparing them for sale.\n",
      "78\n",
      "test_acm/images_test_acm/78.jpg\n",
      "context 1: A controlled detonation was carried out after an unexploded World War Two bomb was found in south-west England. The bomb was discovered in a field near a farm, and authorities took immediate action to ensure public safety. The explosive was deemed too dangerous to be removed or defused, so a controlled detonation was conducted to minimize the risk of an accidental explosion. The area surrounding the bomb was evacuated, and residents were advised to stay indoors while the operation was underway. The controlled detonation helped to prevent any potential harm to the surrounding community and property.\n",
      "context 2: The image shows an unexploded bomb sitting in a field near a house. The bomb is large and appears to be a rock, and it is surrounded by mud and grass. The house is located close to the bomb, indicating that it might be an old or abandoned structure. The presence of the unexploded bomb in the field poses a potential risk and highlights the need for proper disposal or detonation to ensure the safety of the surrounding area and residents.\n",
      "79\n",
      "test_acm/images_test_acm/79.png\n",
      "context 1: In the image, Hillary Clinton is smiling next to Donald Trump, who is wearing a yellow tie. This scene represents a moment of political camaraderie between two individuals who have a significant difference in their political views. Hillary Clinton, as a former Secretary of State and a presidential candidate, might have wished for someone like Donald Trump to run for office, as it would have made her campaign more competitive and potentially led to a different outcome. However, it is important to note that this statement is a subjective interpretation and does not necessarily reflect the actual feelings or opinions of both individuals.\n",
      "context 2: The image shows former President Bill Clinton and former Secretary of State Hillary Clinton posing together at the Trumps' wedding. Multiple media outlets, including CNN, NBC, ABC, The New York Times, and The Hollywood Reporter, have published similar images from that photo op and confirmed that the Clintons did attend the Trump wedding.\n",
      "80\n",
      "test_acm/images_test_acm/80.jpg\n",
      "context 1: The image shows an older man with white hair, wearing a suit and tie, sitting in a chair and looking thoughtful. The man appears to be Dr. James D. Watson, a renowned scientist known for his role in discovering the structure of DNA. The film Decoding Watson, which explores Dr. Watson's views on race, suggests that his scientific brilliance may be contrasted with his views on race, potentially raising questions about the relationship between science and social issues.\n",
      "context 2: The image shows an older man with white hair, wearing a suit and tie, sitting in a chair and looking thoughtful. The man appears to be James Watson, the Nobel Prize-winning scientist behind the double helix, as he confronts his complex legacy.\n",
      "81\n",
      "test_acm/images_test_acm/81.png\n",
      "context 1: This is a false claim. There is no evidence to support that Putin's daughter has died or that she took the COVID-19 vaccine. The image shows a woman taking a blood pressure reading, but it has nothing to do with Putin's daughter or the COVID-19 vaccine.\n",
      "context 2: The image and the video are not the same. The image shows a woman taking a blood pressure test, while the video supposedly showing Putin's daughter taking the vaccine is actually a different person, who is a volunteer unrelated to the Russian president.\n",
      "82\n",
      "test_acm/images_test_acm/82.jpg\n",
      "context 1: Kendrick Lamar, a famous rapper, bought and publicly destroyed the gun used by George Zimmerman to kill Trayvon Martin. This act of destruction was done in front of a crowd of people, as seen in the image, where the crowd is watching the event. The purpose of this act was to raise awareness about gun violence and to symbolize the need for change in the United States, particularly regarding gun laws and the protection of African American lives.\n",
      "context 2: The image shows a man on stage, wearing a black hat and a black jacket, performing in front of a crowd of people. He is holding a microphone and appears to be singing into it. The audience is made up of various individuals, some of whom are holding cell phones, capturing the moment or sharing the experience with others. The scene takes place at an event, likely a concert or a performance, where the man is the main attraction, entertaining the audience with his music and stage presence.\n",
      "83\n",
      "test_acm/images_test_acm/83.jpg\n",
      "context 1: The image shows a U.S. forces outpost on a hilltop in Syria, as seen from the Turkish side of the border. The outpost is located near the city of Ayn Al Arab or Kobani, which is under the control of Kurdish forces. The presence of the U.S. forces in this area suggests that they are involved in the ongoing conflict in Syria, possibly supporting the Kurdish forces in their fight against ISIS or other threats. The image highlights the complex nature of the Syrian conflict and the involvement of various international actors in the region.\n",
      "context 2: The image depicts an abandoned cement factory with a large, empty lot surrounding it. The factory appears to be in a state of disrepair, with no signs of activity or maintenance. The surrounding area consists of a mix of dirt, rocks, and small patches of grass. There are a few small buildings scattered throughout the scene, some of which are in disrepair. The overall atmosphere of the area is one of neglect and decay, reflecting the abandonment of the cement factory by the municipality.\n",
      "84\n",
      "test_acm/images_test_acm/84.jpg\n",
      "context 1: Senator Bernie Sanders, a democratic presidential candidate, has announced his plans to attend a portion of a meeting with former staff members from his 2016 presidential campaign who have raised concerns about sexism and harassment. The meeting is scheduled to take place on January 24, 2020, in Washington D.C. Sanders' decision to attend the meeting reflects his commitment to addressing these issues and ensuring a safe and respectful work environment for his staff and future campaigns.\n",
      "context 2: The image shows Senator Bernie Sanders of Vermont walking out of a news conference after the final Yemen Resolution vote. He is wearing a suit and tie, and he is holding a piece of paper in his hand. The senator appears to be in a hurry, possibly heading to his next appointment or task. The scene captures a moment of political activity and decision-making in the United States.\n",
      "85\n",
      "test_acm/images_test_acm/85.jpg\n",
      "context 1: The image features a double rainbow arching over the Glasgow's famous \"squinty\" bridge, which is a large arched bridge. The bridge is located near a river and is surrounded by a cityscape. The rainbows add a beautiful and serene touch to the urban environment. There are several cars and a bus visible in the scene, indicating that it is a busy city street. The presence of the rainbows and the iconic bridge create a picturesque and memorable scene.\n",
      "context 2: The image features a beautiful rainbow arching over a large bridge in Glasgow, Scotland. The bridge is a long, arched structure with a glass ceiling, and it spans over a river. The rainbow adds a stunning visual effect to the scene, creating a captivating and serene atmosphere. The presence of the river and the bridge also suggest that the location might be a city, as evidenced by the urban surroundings.\n",
      "86\n",
      "test_acm/images_test_acm/86.jpg\n",
      "context 1: The image features Bradley Cooper and Lady Gaga, both contenders for the film \"A Star Is Born.\" In the scene, they are singing together, with Lady Gaga holding a microphone in front of Bradley Cooper. This suggests that the movie is inspired by the 1937 film of the same name and features the same characters, with Lady Gaga playing the role of an aspiring singer and Bradley Cooper playing the role of a seasoned musician who mentors her. The image captures the essence of the film's story and the chemistry between the two main characters.\n",
      "context 2: In the image, Bradley Cooper and Lady Gaga are performing together on stage. Lady Gaga is singing into a microphone, while Bradley Cooper is playing a guitar. They are both dressed in costumes, and their performance appears to be part of a movie scene. The image captures the essence of their collaboration and the emotional connection between the two main characters in \"A Star Is Born.\"\n",
      "87\n",
      "test_acm/images_test_acm/87.jpg\n",
      "context 1: The image shows a poster for the remake of \"Bedknobs and Broomsticks\" with the tagline \"Journey to Enchantment\" and the main character, played by Kate Winslet. The poster is displayed on a wall, and the movie is slated for release in 2018.\n",
      "context 2: The image shows a woman dressed in a blue dress, wearing a tie, and holding a fan. It appears to be a poster for a movie called \"Bedknobs and Broomsticks.\" However, some readers might be confused or misled by the fact that the poster is described as a fan-made movie poster. This could lead them to question the authenticity or legitimacy of the poster, even though it is a representation of a real movie. It is essential to note that the poster is fan-made, and the content might not be entirely accurate or representative of the actual movie.\n",
      "88\n",
      "test_acm/images_test_acm/88.png\n",
      "context 1: There are no photographs in the image description provided. Could you please provide more context or information about the photographs you are referring to?\n",
      "context 2: The statue of Abraham Lincoln, which has been placed in the White House's East Room, will be returned to the Smithsonian Institution, as incoming officials generally choose their own items from among national artefacts to decorate the White House during their term. The Smithsonian Institution is the national museum and research complex, and it houses the collections of historical, scientific, and artistic artifacts. The Lincoln statue is a significant piece of history and art, and it is appropriate for it to remain in the Smithsonian, where it can be displayed and appreciated by the public.\n",
      "89\n",
      "test_acm/images_test_acm/89.png\n",
      "context 1: The image shows a video game simulation of a car driving on a city street, with the car bouncing off the roofs of two other vehicles. The simulation appears to be a part of a game, possibly Grand Theft Auto, where the player is attempting to perform a daring stunt. The scene includes multiple cars, a truck, and a traffic light, all of which are part of the simulation. The video game seems to be capturing the excitement and thrill of the stunt, making it an engaging and entertaining experience for the player.\n",
      "context 2: The image is a computer-generated (CGI) animation, created by a 3D artist using Adobe After Effects, and not an actual photograph of a city street. The artist, who uses the handle @2NCS on social media, has created a video that showcases a traffic jam in a city with various vehicles, including cars and trucks, and a highway overpass. The animation is designed to give the impression of a busy urban environment with heavy traffic.\n",
      "90\n",
      "test_acm/images_test_acm/90.jpg\n",
      "context 1: The image captures a beautiful nighttime view of Edinburgh, Scotland, with its iconic castle illuminated against the backdrop of a clear sky. The cityscape is set against a dark sky, allowing the stars and the planets Jupiter and Saturn to be visible. The presence of these celestial bodies adds a unique and captivating element to the already stunning cityscape. The combination of the illuminated castle, the nighttime cityscape, and the twinkling stars and planets creates a breathtaking and memorable scene.\n",
      "context 2: The image features a nighttime view of the city of Edinburgh, Scotland, with its iconic castle illuminated against a dark sky. The castle is surrounded by a row of buildings, creating a picturesque scene. In the foreground, there are two prominently visible traffic lights, adding a touch of urban life to the scene. The cityscape is further enhanced by the presence of Jupiter and Saturn, which appear as bright lights in the sky above the city. This combination of natural and man-made elements creates a captivating and beautiful image of the city at night.\n",
      "91\n",
      "test_acm/images_test_acm/91.jpg\n",
      "context 1: The image depicts a group of people walking along a snow-covered road, possibly in a mountainous area. The snow has piled up on both sides of the road, creating a barrier that the people are navigating. There are at least 13 people visible in the scene, some of whom are carrying backpacks. They appear to be walking in a line, possibly as part of a guided tour or an organized event. The snow-covered road and the presence of people suggest that the location might be a ski resort or a mountainous region where heavy snowfall is common.\n",
      "context 2: The image shows a snow-covered road with a group of people walking along it. The snow is piled up on both sides of the road, creating a path for the pedestrians. The people are walking in a line, indicating that they might be following a designated route or path. The scene suggests that it could be a popular winter destination or a location experiencing heavy snowfall.\n",
      "92\n",
      "test_acm/images_test_acm/92.jpg\n",
      "context 1: The image is a black and white photo of a busy city street in Zurich, Switzerland. The street is filled with cars, buses, and people. There are several cars parked and driving along the street, with one car in the foreground and others further back. A bus can be seen on the left side of the street, and another bus is located in the middle of the scene.Numerous people are walking along the sidewalk, with some closer to the camera and others further away. A few individuals are carrying handbags, indicating that they might be shopping or running errands. The overall atmosphere of the photo is bustling and lively, capturing the essence of city life in Zurich.\n",
      "context 2: There are two cars in the street, one old and one new, parked next to each other.\n",
      "93\n",
      "test_acm/images_test_acm/93.jpg\n",
      "context 1: This information is not accurate. Vice President Mike Pence did not visit Iceland today, and there was no law preventing him from entering the country. The Vice President was in Norway for a meeting with Prime Minister Erna Solberg.\n",
      "context 2: The Vice President Mike Pence was not booted from Iceland. The term \"booted\" is used figuratively to describe the situation where he was not allowed to enter a particular location or was not granted access to a specific event. The actual event that occurred was that Mike Pence was not invited to speak at an event in Iceland, and he chose not to attend.\n",
      "94\n",
      "test_acm/images_test_acm/94.png\n",
      "context 1: The image shows a man in a red and black outfit, likely a Maasai warrior, performing a traditional dance. The Maasai tribe has a rich cultural heritage and are known for their colorful dress and dances. It is possible that the Kenyan government is using the Maasai tribe for the curfew because they have a strong sense of community and are easily recognizable, making them an effective deterrent for potential lawbreakers. However, it is important to note that this is just one possible interpretation of the image and not an official statement from the Kenyan government.\n",
      "context 2: The image shows a man in a red and black outfit, who appears to be a Maasai warrior, standing in a room and making a funny face. He is not whipping anyone, and the scene does not depict him in a professional capacity. The image is more likely a lighthearted or humorous moment captured during the COVID-19 pandemic in Kenya.\n",
      "95\n",
      "test_acm/images_test_acm/95.jpg\n",
      "context 1: The image shows a volcano spewing out a large amount of ash and smoke, which indicates a significant eruption. Volcanic eruptions can have a significant impact on the environment and climate. A single eruption from a volcano can release a large amount of ash, gas, and other particles into the atmosphere, which can lead to various effects such as air pollution, disruption of air travel, and changes in climate. In fact, a single eruption from a volcano can put 10,000 times more carbon dioxide into the atmosphere than all of human activity has throughout history. This highlights the importance of monitoring and understanding volcanic activity to minimize the potential impacts on the environment and human life.\n",
      "context 2: The image features a volcano with a large cloud of smoke and ash rising from it, indicating an active eruption. The volcano is located in a remote area, possibly in the Arctic, and is surrounded by a vast, snow-covered landscape. The powerful eruption of the volcano is creating a significant plume of ash and smoke, which can be observed in the atmosphere. The presence of this volcano in such a remote location highlights the importance of monitoring and understanding volcanic activity in various regions of the world.\n",
      "96\n",
      "test_acm/images_test_acm/96.jpg\n",
      "context 1: The image shows a woman walking past a mural on a building, which is designed to remind Abidjan's residents of anti-coronavirus hygiene measures. The mural features a painting of a man wearing a surgical mask and glasses, with a message in French. The woman is also wearing a mask as she walks by the mural, demonstrating the city's commitment to promoting and maintaining health and safety practices during the pandemic.\n",
      "context 2: The image shows a woman walking down a street while wearing a face mask and holding a bottle. She is passing by a wall that has graffiti on it, which is likely related to the hygiene measures during the COVID-19 pandemic. The woman appears to be following the guidelines and taking necessary precautions to protect herself and others from the virus.\n",
      "97\n",
      "test_acm/images_test_acm/97.jpg\n",
      "context 1: The image depicts an old man leaning against his truck in a rural setting, with a fire visible in the background. The fire appears to be spreading, and the man seems concerned about the situation. The truck is parked on the side of the road, and there are several other vehicles nearby, including a couple of cars and a bus. The scene suggests that the man is monitoring the fire and trying to assess the potential impact on his property or the surrounding area.\n",
      "context 2: The East Troublesome fire, which started on September 1st, has grown significantly, and residents have been evacuated from the area near Granby, Colorado. The fire has now reached over 10,000 acres, and it is spreading rapidly due to the dry conditions and strong winds. The fire is threatening the town of Paragon, and the nearby communities are taking precautionary measures to ensure their safety. Residents have been advised to evacuate their homes and seek shelter in nearby towns or with friends and family. The fire has also led to the closure of several roads and highways, including Highway 113, as a safety measure. Firefighters and emergency personnel are working tirelessly to contain the fire and protect the lives and property of the residents in the area.\n",
      "98\n",
      "test_acm/images_test_acm/98.jpg\n",
      "context 1: In the image, a truck is being launched via a catapult off the deck of the USS Gerald Ford, a large aircraft carrier. The truck is in mid-air, soaring through the air as it is propelled by the powerful catapult system. The scene showcases the impressive technology and capabilities of the USS Gerald Ford and the United States Navy.\n",
      "context 2: The image shows a large naval ship with several smaller boats around it, floating on a body of water. The presence of these boats suggests that they are part of the naval fleet, and they might be used for various purposes such as transportation, training, or even for specific missions. The fact that they are docked together indicates that they are likely being utilized for a coordinated operation or event. It is not uncommon for naval vessels to have smaller boats attached to them for various reasons, and the presence of these boats does not necessarily imply wastefulness.\n",
      "99\n",
      "test_acm/images_test_acm/99.jpg\n",
      "context 1: The image depicts a quiet street near Potsdamer Platz in Berlin on a Tuesday afternoon. There are several traffic lights visible along the street, with one person crossing the street at a crosswalk. The street appears to be relatively empty, with no cars or other pedestrians in the immediate vicinity. The scene suggests a calm and peaceful atmosphere in the city, possibly during a time when fewer people are out and about.\n",
      "context 2: The image depicts a city street with a person walking down the sidewalk, and multiple traffic lights are visible. The presence of the traffic lights and the person walking indicate that the street is active and functional. However, the statement that the German capital, Berlin, has turned into a ghost town due to the Corona virus pandemic is not supported by the image. The city appears to be functioning as usual, with people walking and traffic lights in place, which contradicts the notion of a ghost town.\n",
      "100\n",
      "test_acm/images_test_acm/100.png\n",
      "context 1: The image is a fake news story, created to spread misinformation. Ricky Ellsworth is not a real person, and the story about her death at the hands of a black police officer is fabricated.\n",
      "context 2: The woman in the photograph is not \"Ricky Ellsworth.\" The error in the caption is due to the misidentification of the woman in the image. It is important to verify and correct the information displayed in the captions to ensure accuracy and avoid misleading the viewers.\n",
      "101\n",
      "test_acm/images_test_acm/101.jpg\n",
      "context 1: The image shows a protest taking place in front of a building, with a large crowd of people gathered. Among the crowd, there are several individuals wearing masks, possibly as a form of anonymity or to express solidarity with the cause. The protest appears to be peaceful, as the police are present to maintain order but do not seem to be actively intervening in the demonstration. The scene suggests that the people are voicing their opinions and concerns regarding labor policies, as they gather outside the building where the Prime Minister is located.\n",
      "context 2: The image shows a protest taking place outside a TV building, with a large drawing of Hungarian President Viktor Orban displayed prominently on the building's wall. There are several people gathered in the street, some of them holding signs, expressing their dissatisfaction with the current political situation. The crowd is diverse, with people of various ages and appearances participating in the protest. The protesters are standing in front of the building, making their voices heard and demanding change in the political landscape.\n",
      "102\n",
      "test_acm/images_test_acm/102.jpg\n",
      "context 1: In the image, a memorial is set up for a man who passed away, with a painting of angels on the wall and a bench nearby. A person is kneeling in front of the memorial, possibly paying their respects or reflecting on the loss. The scene suggests that the man who passed away was a notable figure, possibly a famous boxer, as indicated by the presence of a poster of him. The memorial serves as a tribute to his life and legacy, and the person kneeling in front of it may be a friend, family member, or fan who is deeply affected by his passing.\n",
      "context 2: The image depicts a man kneeling in front of a memorial and mural that honors the life of a famous rapper who passed away. The mural features a painting of a dove flying over a heart, symbolizing the artist's passing. The man appears to be paying his respects to the late rapper, showing his appreciation and remembrance for the artist's work and legacy.\n",
      "103\n",
      "test_acm/images_test_acm/103.jpg\n",
      "context 1: The image features a postal worker in the East Village neighborhood of Manhattan, sitting on a fire hydrant and surrounded by trash. The worker is wearing a mask, likely to protect against the spread of a contagious disease. The scene takes place on a street corner, with a trash can nearby and a box truck parked in the background. The postal worker appears to be taking a break or waiting for something, while the trash and the parked truck suggest that the area might be experiencing some waste management issues or a lack of proper disposal facilities.\n",
      "context 2: The image shows a postal worker wearing a mask and a hat, standing next to a mailbox on the sidewalk. This scene reflects the current situation where the postal service is still functioning despite the COVID-19 pandemic. The postal worker is required to wear a mask and follow safety protocols to protect both themselves and the public. The mailbox, despite being an essential part of the postal service, might be an object of concern due to its proximity to the worker and the public. It is crucial for the postal service to ensure that mailboxes are regularly cleaned and disinfected to minimize the risk of spreading the virus. The postal worker's dedication to their job amidst the pandemic demonstrates the resilience and commitment of the workforce in continuing to provide essential services during challenging times.\n",
      "104\n",
      "test_acm/images_test_acm/104.png\n",
      "context 1: In the image, President Joe Biden is sitting at his desk in the Oval Office, signing an executive order. The executive order allows the United States to fund abortions abroad. This action reflects President Biden's commitment to reproductive rights and women's health, as well as his promise to expand access to abortion services globally.\n",
      "context 2: In the image, President Biden is sitting at his desk in the Oval Office, signing a document. However, none of the moves by Biden, as of yet, authorize the United States government to fund abortions abroad. It is important to note that the image does not provide information about the specific document or its content, so it is not possible to determine whether or not it relates to the funding of abortions abroad. As of now, the official position of the Biden administration on this matter remains unclear.\n",
      "105\n",
      "test_acm/images_test_acm/105.jpg\n",
      "context 1: The image shows a man on stage, wearing a black hat and a black jacket, performing in front of a crowd of people. He is holding a microphone and singing into it, capturing the attention of the audience. The audience consists of multiple individuals, some of whom are holding cell phones, possibly taking pictures or recording the performance. The scene appears to be a concert or a live performance, with the man on stage being the main focus of the audience's attention.\n",
      "context 2: The image captures a lively concert scene with a crowd of people gathered around the stage. The main focus is on a man standing on the stage, singing into a microphone. The singer appears to be Kendrick Lamar, as he is holding his finger up in the air, possibly during his performance. The audience is engaged and attentive, with some of them holding their hands up in the air as well. The atmosphere is energetic, and the crowd seems to be enjoying the music and the performance.\n",
      "106\n",
      "test_acm/images_test_acm/106.jpg\n",
      "context 1: The image shows a woman cutting the fur of two small dogs, Magnum and Monica, who are sitting on stools in a grooming area. The woman is using scissors to trim their fur, ensuring their appearance is well-maintained. In addition to the two dogs being groomed, there is another dog, Honey, who is also present in the grooming area. The dogs are sitting on various stools, with one placed near the woman, another closer to the right side of the image, and the third one further back. The grooming area is equipped with a chair, and there are multiple bottles placed around the space, likely containing grooming products or supplies.\n",
      "context 2: The image depicts a woman cutting a dog's hair in a pet salon in Bangkok. The dog is sitting on a chair, and the woman is using scissors to groom the dog. The salon is well-equipped with several chairs, some of which are occupied by other dogs. There are at least four other dogs in the salon, with some sitting on chairs and others standing nearby. The salon also features a sink, which is likely used for cleaning and grooming the pets. The overall atmosphere of the salon suggests a professional and comfortable environment for pet grooming and care.\n",
      "107\n",
      "test_acm/images_test_acm/107.jpg\n",
      "context 1: In the image, a group of people, including a community leader named Janet Sharty, are handing out popcorn, lollipops, and biscuits to children as New Year's gifts. The children are smiling and enjoying the festive atmosphere. The scene takes place in a yard, where a dining table is set up with the gifts and treats. There are several people in the image, including the community leader and the children, all participating in this joyful event.\n",
      "context 2: In the image, a group of children is gathered outdoors, smiling and holding their wrapped sweets. They seem to be enjoying their time together and sharing their treats with each other. There are at least six children visible in the scene, with some of them standing closer to the camera and others further back. The children are holding their wrapped sweets in various positions, with some sweets being more visible than others. The scene appears to be a joyful and lively celebration, possibly during a holiday or special event.\n",
      "108\n",
      "test_acm/images_test_acm/108.jpg\n"
     ]
    }
   ],
   "source": [
    "data = read_json(json_test_file)\n",
    "\n",
    "# Define the full path to the images directory\n",
    "images_directory = INPUT_FOLDER + \"/images_test_acm\"\n",
    "for index, item in enumerate(data):\n",
    "    print(index)\n",
    "    image_filename = os.path.basename(item[\"img_local_path\"])\n",
    "    image_path = os.path.join(images_directory, image_filename)\n",
    "    print(image_path)\n",
    "    prompt1 = item[\"caption1\"]\n",
    "    prompt2 = item[\"caption2\"]\n",
    "    context1, context2 = inference(image_path, prompt1, prompt2)\n",
    "    print(f\"context 1: {context1}\")\n",
    "    print(f\"context 2: {context2}\")\n",
    "    item[\"context1\"] = context1\n",
    "    item[\"context2\"] = context2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the updated data back to the JSON file\n",
    "with open('context_test.json', 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Đường dẫn đến tệp JSON của bạn\n",
    "json_file = \"context_test.json\"\n",
    "\n",
    "# Đọc dữ liệu từ tệp JSON\n",
    "with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Chuyển đổi dữ liệu thành DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context_combined'] = df['context1'] + \"\\n\" + df['context2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = df['context_combined'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\"\n",
    "repository_id = \"hoanghoavienvo/roberta-base-detect-cheapfake-combined-train-test-15200-2-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(repository_id)\n",
    "model_info = model.__dict__\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training = False\n",
    "\n",
    "# Chuẩn bị tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(repository_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "# Chạy model trên tập test\n",
    "for sentence in test_sentences:\n",
    "    inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "    inputs.to(device)\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = outputs.logits.softmax(dim=1)\n",
    "    _, predicted_class = torch.max(probabilities, dim=1)\n",
    "    predictions.append(predicted_class.item())\n",
    "\n",
    "# Lưu kết quả vào DataFrame\n",
    "results = pd.DataFrame({'text': test_sentences, 'predicted_label': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tính toán classification report\n",
    "report = classification_report(df['context_label'], predictions, digits = 3)\n",
    "\n",
    "# In ra classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
